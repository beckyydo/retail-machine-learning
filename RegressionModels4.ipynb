{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whole Numbers,2 Targets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Store</th>\n",
       "      <th>Start_of_Week</th>\n",
       "      <th>Week_Date</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Week</th>\n",
       "      <th>Year</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Holiday_Name</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-30</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>2.57</td>\n",
       "      <td>211.0964</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>6.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1643690.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-06</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>2.55</td>\n",
       "      <td>211.2422</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1641957.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-13</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>2.51</td>\n",
       "      <td>211.2891</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>7</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1611968.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-20</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>2.56</td>\n",
       "      <td>211.3196</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>8</td>\n",
       "      <td>2010</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1409727.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-27</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>2.62</td>\n",
       "      <td>211.3501</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>9</td>\n",
       "      <td>2010</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1554806.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ID  Store Start_of_Week   Week_Date  Fuel_Price       CPI  \\\n",
       "0           0   0      1    2010-01-30  2010-02-05        2.57  211.0964   \n",
       "1           1   1      1    2010-02-06  2010-02-12        2.55  211.2422   \n",
       "2           2   2      1    2010-02-13  2010-02-19        2.51  211.2891   \n",
       "3           3   3      1    2010-02-20  2010-02-26        2.56  211.3196   \n",
       "4           4   4      1    2010-02-27  2010-03-05        2.62  211.3501   \n",
       "\n",
       "   Unemployment Type    Size  Week  Year  Temperature_C Holiday_Name  \\\n",
       "0         8.106    A  151315     5  2010            6.0   No Holiday   \n",
       "1         8.106    A  151315     6  2010            4.0   No Holiday   \n",
       "2         8.106    A  151315     7  2010            4.0   No Holiday   \n",
       "3         8.106    A  151315     8  2010            8.0   No Holiday   \n",
       "4         8.106    A  151315     9  2010            8.0   No Holiday   \n",
       "\n",
       "   Weekly_Sales  \n",
       "0    1643690.90  \n",
       "1    1641957.44  \n",
       "2    1611968.17  \n",
       "3    1409727.59  \n",
       "4    1554806.68  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart = pd.read_csv('walmartdata.csv')\n",
    "walmart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalave = walmart.groupby([\"Store\"])[\"Weekly_Sales\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Store</th>\n",
       "      <th>Start_of_Week</th>\n",
       "      <th>Week_Date</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Week</th>\n",
       "      <th>Year</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Holiday_Name</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Ave_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-30</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>2.57</td>\n",
       "      <td>211.0964</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>6.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1643690.90</td>\n",
       "      <td>1.555264e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-06</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>2.55</td>\n",
       "      <td>211.2422</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1641957.44</td>\n",
       "      <td>1.555264e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-13</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>2.51</td>\n",
       "      <td>211.2891</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>7</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1611968.17</td>\n",
       "      <td>1.555264e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-20</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>2.56</td>\n",
       "      <td>211.3196</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>8</td>\n",
       "      <td>2010</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1409727.59</td>\n",
       "      <td>1.555264e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-27</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>2.62</td>\n",
       "      <td>211.3501</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>9</td>\n",
       "      <td>2010</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1554806.68</td>\n",
       "      <td>1.555264e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>6434</td>\n",
       "      <td>6434</td>\n",
       "      <td>45</td>\n",
       "      <td>2012-09-22</td>\n",
       "      <td>2012-09-28</td>\n",
       "      <td>4.00</td>\n",
       "      <td>192.0136</td>\n",
       "      <td>8.684</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "      <td>39</td>\n",
       "      <td>2012</td>\n",
       "      <td>18.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>713173.95</td>\n",
       "      <td>7.859814e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6435</th>\n",
       "      <td>6435</td>\n",
       "      <td>6435</td>\n",
       "      <td>45</td>\n",
       "      <td>2012-09-29</td>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>3.98</td>\n",
       "      <td>192.1704</td>\n",
       "      <td>8.667</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "      <td>40</td>\n",
       "      <td>2012</td>\n",
       "      <td>18.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>733455.07</td>\n",
       "      <td>7.859814e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6436</th>\n",
       "      <td>6436</td>\n",
       "      <td>6436</td>\n",
       "      <td>45</td>\n",
       "      <td>2012-10-06</td>\n",
       "      <td>2012-10-12</td>\n",
       "      <td>4.00</td>\n",
       "      <td>192.3273</td>\n",
       "      <td>8.667</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "      <td>41</td>\n",
       "      <td>2012</td>\n",
       "      <td>12.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>734464.36</td>\n",
       "      <td>7.859814e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6437</th>\n",
       "      <td>6437</td>\n",
       "      <td>6437</td>\n",
       "      <td>45</td>\n",
       "      <td>2012-10-13</td>\n",
       "      <td>2012-10-19</td>\n",
       "      <td>3.97</td>\n",
       "      <td>192.3309</td>\n",
       "      <td>8.667</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "      <td>42</td>\n",
       "      <td>2012</td>\n",
       "      <td>14.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>718125.53</td>\n",
       "      <td>7.859814e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>6438</td>\n",
       "      <td>6438</td>\n",
       "      <td>45</td>\n",
       "      <td>2012-10-20</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>3.88</td>\n",
       "      <td>192.3089</td>\n",
       "      <td>8.667</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "      <td>43</td>\n",
       "      <td>2012</td>\n",
       "      <td>15.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>760281.43</td>\n",
       "      <td>7.859814e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6439 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    ID  Store Start_of_Week   Week_Date  Fuel_Price       CPI  \\\n",
       "0              0     0      1    2010-01-30  2010-02-05        2.57  211.0964   \n",
       "1              1     1      1    2010-02-06  2010-02-12        2.55  211.2422   \n",
       "2              2     2      1    2010-02-13  2010-02-19        2.51  211.2891   \n",
       "3              3     3      1    2010-02-20  2010-02-26        2.56  211.3196   \n",
       "4              4     4      1    2010-02-27  2010-03-05        2.62  211.3501   \n",
       "...          ...   ...    ...           ...         ...         ...       ...   \n",
       "6434        6434  6434     45    2012-09-22  2012-09-28        4.00  192.0136   \n",
       "6435        6435  6435     45    2012-09-29  2012-10-05        3.98  192.1704   \n",
       "6436        6436  6436     45    2012-10-06  2012-10-12        4.00  192.3273   \n",
       "6437        6437  6437     45    2012-10-13  2012-10-19        3.97  192.3309   \n",
       "6438        6438  6438     45    2012-10-20  2012-10-26        3.88  192.3089   \n",
       "\n",
       "      Unemployment Type    Size  Week  Year  Temperature_C Holiday_Name  \\\n",
       "0            8.106    A  151315     5  2010            6.0   No Holiday   \n",
       "1            8.106    A  151315     6  2010            4.0   No Holiday   \n",
       "2            8.106    A  151315     7  2010            4.0   No Holiday   \n",
       "3            8.106    A  151315     8  2010            8.0   No Holiday   \n",
       "4            8.106    A  151315     9  2010            8.0   No Holiday   \n",
       "...            ...  ...     ...   ...   ...            ...          ...   \n",
       "6434         8.684    B  118221    39  2012           18.0   No Holiday   \n",
       "6435         8.667    B  118221    40  2012           18.0   No Holiday   \n",
       "6436         8.667    B  118221    41  2012           12.0   No Holiday   \n",
       "6437         8.667    B  118221    42  2012           14.0   No Holiday   \n",
       "6438         8.667    B  118221    43  2012           15.0   No Holiday   \n",
       "\n",
       "      Weekly_Sales     Ave_Sales  \n",
       "0       1643690.90  1.555264e+06  \n",
       "1       1641957.44  1.555264e+06  \n",
       "2       1611968.17  1.555264e+06  \n",
       "3       1409727.59  1.555264e+06  \n",
       "4       1554806.68  1.555264e+06  \n",
       "...            ...           ...  \n",
       "6434     713173.95  7.859814e+05  \n",
       "6435     733455.07  7.859814e+05  \n",
       "6436     734464.36  7.859814e+05  \n",
       "6437     718125.53  7.859814e+05  \n",
       "6438     760281.43  7.859814e+05  \n",
       "\n",
       "[6439 rows x 16 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(walmart)):\n",
    "    walmart.loc[i, \"Ave_Sales\"] = totalave[walmart.loc[i, \"Store\"]]\n",
    "walmart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart = walmart.filter(items=['Fuel_Price', \"CPI\", \"Unemployment\", \"Temperature_C\", \"Weekly_Sales\",\"Ave_Sales\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart.loc[walmart['Weekly_Sales'] > (1.15 * walmart[\"Ave_Sales\"]), 'Label'] = 'Above' \n",
    "walmart.loc[walmart['Weekly_Sales'] < (1.15 * walmart[\"Ave_Sales\"]), 'Label'] = 'Average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart = walmart.filter(items=['Fuel_Price', \"CPI\", \"Unemployment\", \"Temperature_C\", \"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Average    5939\n",
       "Above       500\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6439, 4) (6439,)\n"
     ]
    }
   ],
   "source": [
    "X = walmart.drop(\"Label\", axis=1)\n",
    "y = walmart[\"Label\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# Scale and train x value datasets\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=42)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9242079105404846\n",
      "Testing Data Score: 0.9167701863354037\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10, 50],\n",
    "              'solver': ['newton-cg', 'liblinear', 'sag', 'saga'],\n",
    "             'max_iter':[200, 500, 1000]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] C=1, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=200, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=200, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=200, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=200, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=newton-cg .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . C=1, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=500, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=500, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=500, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=500, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=1, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=1, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=1, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=1, max_iter=1000, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=1, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=1, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=1, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=1, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=1, max_iter=1000, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=1, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=1, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=1, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=1, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=1, max_iter=1000, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=1, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=1, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=1, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=1, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=1, max_iter=1000, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=1, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=200, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=200, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=200, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=200, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=newton-cg .............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . C=5, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=500, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=500, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=500, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=500, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=5, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=5, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=5, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=5, max_iter=1000, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=5, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=5, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=5, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=5, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=5, max_iter=1000, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=5, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=5, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=5, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=5, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=5, max_iter=1000, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=5, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=5, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=5, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=5, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=5, max_iter=1000, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=5, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=200, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=200, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=200, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=200, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=newton-cg ............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=500, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=500, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=500, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=500, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=10, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=10, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=10, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=10, max_iter=1000, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=10, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=10, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=10, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=10, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=10, max_iter=1000, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=10, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=200, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=200, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=200, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=200, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=saga .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=50, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=500, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=500, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=500, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=500, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=50, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=50, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=50, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=50, max_iter=1000, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=50, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=50, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=50, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=50, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=50, max_iter=1000, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=50, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={'C': [1, 5, 10, 50], 'max_iter': [200, 500, 1000],\n",
       "                         'solver': ['newton-cg', 'liblinear', 'sag', 'saga']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'max_iter': 200, 'solver': 'newton-cg'}\n",
      "0.9242079404413264\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9242079105404846\n",
      "Testing Data Score: 0.9167701863354037\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1, max_iter=200, solver= 'newton-cg', random_state=42)\n",
    "logreg.fit(X_train_scaled, encoded_y_train)\n",
    "print(f\"Training Data Score: {logreg.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {logreg.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = walmart[\"Label\"]\n",
    "target_names = [\"Above\", \"Average\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9397515527950311"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf = rf.fit(X_train_scaled, encoded_y_train)\n",
    "rf.score(X_test_scaled, encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3311428636926653, 'CPI'),\n",
       " (0.2694866326503375, 'Fuel_Price'),\n",
       " (0.20966494957819504, 'Temperature_C'),\n",
       " (0.18970555407880219, 'Unemployment')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = walmart.columns\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'criterion': ['gini', 'entropy'],\n",
    "              'splitter': ['best', 'random'],\n",
    "             'class_weight': ['None', 'balanced']}\n",
    "grid = GridSearchCV(rf, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] class_weight=None, criterion=gini, splitter=best ................\n",
      "[CV]  class_weight=None, criterion=gini, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=best ................\n",
      "[CV]  class_weight=None, criterion=gini, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=best ................\n",
      "[CV]  class_weight=None, criterion=gini, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=best ................\n",
      "[CV]  class_weight=None, criterion=gini, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=best ................\n",
      "[CV]  class_weight=None, criterion=gini, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=random ..............\n",
      "[CV]  class_weight=None, criterion=gini, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=random ..............\n",
      "[CV]  class_weight=None, criterion=gini, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=random ..............\n",
      "[CV]  class_weight=None, criterion=gini, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=random ..............\n",
      "[CV]  class_weight=None, criterion=gini, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=random ..............\n",
      "[CV]  class_weight=None, criterion=gini, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=best .............\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=best .............\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=best .............\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=best .............\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=best .............\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=random ...........\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=random ...........\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=random ...........\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=random ...........\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=random ...........\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=best ............\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=best, score=0.845, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=best ............\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=best, score=0.850, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=best ............\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=best, score=0.852, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=best ............\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=best, score=0.848, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=best ............\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=best, score=0.835, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=random ..........\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=random, score=0.830, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=random ..........\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=random, score=0.852, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=random ..........\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=random, score=0.853, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=random ..........\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=random, score=0.827, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=random ..........\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=random, score=0.824, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=best .........\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=best, score=0.843, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=best .........\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=best, score=0.856, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=best .........\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=best, score=0.836, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=best .........\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=best, score=0.855, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=best .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  class_weight=balanced, criterion=entropy, splitter=best, score=0.851, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=random .......\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=random, score=0.829, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=random .......\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=random, score=0.827, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=random .......\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=random, score=0.836, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=random .......\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=random, score=0.839, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=random .......\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=random, score=0.829, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'class_weight': ['None', 'balanced'],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'splitter': 'best'}\n",
      "0.8482092706422512\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9397515527950311"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranfor = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "ranfor = ranfor.fit(X_train_scaled, encoded_y_train)\n",
    "ranfor.score(X_test_scaled, encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9254658385093167"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf = clf.fit(X_train_scaled, encoded_y_train)\n",
    "clf.score(X_test_scaled, encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.36486851439318435, 'CPI'),\n",
       " (0.27004417922651425, 'Fuel_Price'),\n",
       " (0.182869784976228, 'Unemployment'),\n",
       " (0.1822175214040735, 'Temperature_C')]"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = walmart.columns\n",
    "sorted(zip(clf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'criterion': ['gini', 'entropy'],\n",
    "              'splitter': ['best', 'random'],\n",
    "             'class_weight': ['None', 'balanced']}\n",
    "grid = GridSearchCV(clf, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] class_weight=None, criterion=gini, splitter=best ................\n",
      "[CV]  class_weight=None, criterion=gini, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=best ................\n",
      "[CV]  class_weight=None, criterion=gini, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=best ................\n",
      "[CV]  class_weight=None, criterion=gini, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=best ................\n",
      "[CV]  class_weight=None, criterion=gini, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=best ................\n",
      "[CV]  class_weight=None, criterion=gini, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=random ..............\n",
      "[CV]  class_weight=None, criterion=gini, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=random ..............\n",
      "[CV]  class_weight=None, criterion=gini, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=random ..............\n",
      "[CV]  class_weight=None, criterion=gini, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=random ..............\n",
      "[CV]  class_weight=None, criterion=gini, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=random ..............\n",
      "[CV]  class_weight=None, criterion=gini, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=best .............\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=best .............\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=best .............\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=best .............\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=best .............\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=random ...........\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=random ...........\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=random ...........\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=random ...........\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=random ...........\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=best ............\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=best, score=0.845, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=best ............\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=best, score=0.850, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=best ............\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=best, score=0.852, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=best ............\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=best, score=0.848, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=best ............\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=best, score=0.835, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=random ..........\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=random, score=0.830, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=random ..........\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=random, score=0.852, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=random ..........\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=random, score=0.853, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=random ..........\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=random, score=0.827, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=random ..........\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=random, score=0.824, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=best .........\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=best, score=0.843, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=best .........\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=best, score=0.856, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=best .........\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=best, score=0.836, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=best .........\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=best, score=0.855, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=best .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  class_weight=balanced, criterion=entropy, splitter=best, score=0.851, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=random .......\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=random, score=0.829, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=random .......\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=random, score=0.827, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=random .......\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=random, score=0.836, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=random .......\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=random, score=0.839, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=random .......\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=random, score=0.829, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'class_weight': ['None', 'balanced'],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'splitter': 'best'}\n",
      "0.8482092706422512\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9254658385093167"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dectre = tree.DecisionTreeClassifier(random_state=42)\n",
    "dectre = dectre.fit(X_train_scaled, encoded_y_train)\n",
    "dectre.score(X_test_scaled, encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dectre_predictions = dectre.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranfor_predictions = ranfor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Above       0.72      0.45      0.55       134\n",
      "     Average       0.95      0.98      0.97      1476\n",
      "\n",
      "    accuracy                           0.94      1610\n",
      "   macro avg       0.84      0.72      0.76      1610\n",
      "weighted avg       0.93      0.94      0.93      1610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(encoded_y_test, ranfor_predictions,\n",
    "                            target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Above       0.55      0.57      0.56       134\n",
      "     Average       0.96      0.96      0.96      1476\n",
      "\n",
      "    accuracy                           0.93      1610\n",
      "   macro avg       0.76      0.76      0.76      1610\n",
      "weighted avg       0.93      0.93      0.93      1610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(encoded_y_test, dectre_predictions,\n",
    "                            target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.487440</td>\n",
       "      <td>223.461145</td>\n",
       "      <td>6.627970</td>\n",
       "      <td>17.659895</td>\n",
       "      <td>1.529256e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-28</td>\n",
       "      <td>1</td>\n",
       "      <td>3.472333</td>\n",
       "      <td>223.443172</td>\n",
       "      <td>6.634452</td>\n",
       "      <td>16.448992</td>\n",
       "      <td>1.587566e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-04</td>\n",
       "      <td>1</td>\n",
       "      <td>3.456623</td>\n",
       "      <td>223.409742</td>\n",
       "      <td>6.623966</td>\n",
       "      <td>15.104578</td>\n",
       "      <td>1.678286e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.441573</td>\n",
       "      <td>223.372609</td>\n",
       "      <td>6.592424</td>\n",
       "      <td>13.620766</td>\n",
       "      <td>1.742059e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-18</td>\n",
       "      <td>1</td>\n",
       "      <td>3.423539</td>\n",
       "      <td>223.358492</td>\n",
       "      <td>6.556789</td>\n",
       "      <td>12.028795</td>\n",
       "      <td>1.765627e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Store  Fuel_Price         CPI  Unemployment  Temperature_C  \\\n",
       "0  2012-10-21      1    3.487440  223.461145      6.627970      17.659895   \n",
       "1  2012-10-28      1    3.472333  223.443172      6.634452      16.448992   \n",
       "2  2012-11-04      1    3.456623  223.409742      6.623966      15.104578   \n",
       "3  2012-11-11      1    3.441573  223.372609      6.592424      13.620766   \n",
       "4  2012-11-18      1    3.423539  223.358492      6.556789      12.028795   \n",
       "\n",
       "   Weekly_Sales  \n",
       "0  1.529256e+06  \n",
       "1  1.587566e+06  \n",
       "2  1.678286e+06  \n",
       "3  1.742059e+06  \n",
       "4  1.765627e+06  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predix = pd.read_csv('prophet_predictions.csv')\n",
    "predix = predix.drop(['Unnamed: 0'], axis=1)\n",
    "predix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Temperature_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.487440</td>\n",
       "      <td>223.461145</td>\n",
       "      <td>6.627970</td>\n",
       "      <td>17.659895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.472333</td>\n",
       "      <td>223.443172</td>\n",
       "      <td>6.634452</td>\n",
       "      <td>16.448992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.456623</td>\n",
       "      <td>223.409742</td>\n",
       "      <td>6.623966</td>\n",
       "      <td>15.104578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.441573</td>\n",
       "      <td>223.372609</td>\n",
       "      <td>6.592424</td>\n",
       "      <td>13.620766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.423539</td>\n",
       "      <td>223.358492</td>\n",
       "      <td>6.556789</td>\n",
       "      <td>12.028795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>4.393188</td>\n",
       "      <td>195.136141</td>\n",
       "      <td>8.878137</td>\n",
       "      <td>16.570370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>4.400800</td>\n",
       "      <td>195.177228</td>\n",
       "      <td>8.872678</td>\n",
       "      <td>15.371153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>4.394871</td>\n",
       "      <td>195.161653</td>\n",
       "      <td>8.877326</td>\n",
       "      <td>13.409695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>4.380892</td>\n",
       "      <td>195.115184</td>\n",
       "      <td>8.887845</td>\n",
       "      <td>11.328064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>4.374071</td>\n",
       "      <td>195.052613</td>\n",
       "      <td>8.895672</td>\n",
       "      <td>10.263839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2475 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fuel_Price         CPI  Unemployment  Temperature_C\n",
       "0       3.487440  223.461145      6.627970      17.659895\n",
       "1       3.472333  223.443172      6.634452      16.448992\n",
       "2       3.456623  223.409742      6.623966      15.104578\n",
       "3       3.441573  223.372609      6.592424      13.620766\n",
       "4       3.423539  223.358492      6.556789      12.028795\n",
       "...          ...         ...           ...            ...\n",
       "2470    4.393188  195.136141      8.878137      16.570370\n",
       "2471    4.400800  195.177228      8.872678      15.371153\n",
       "2472    4.394871  195.161653      8.877326      13.409695\n",
       "2473    4.380892  195.115184      8.887845      11.328064\n",
       "2474    4.374071  195.052613      8.895672      10.263839\n",
       "\n",
       "[2475 rows x 4 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predix\n",
    "X = predix.drop(\"Date\", axis=1)\n",
    "X = X.drop(\"Store\", axis=1)\n",
    "X = X.drop(\"Weekly_Sales\", axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "predix_scaled = X_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranfor_labels = ranfor.predict(predix_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Average', 'Average', 'Average', ..., 'Average', 'Average',\n",
       "       'Average'], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranfor_labels = label_encoder.inverse_transform(ranfor_labels)\n",
    "ranfor_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.487440</td>\n",
       "      <td>223.461145</td>\n",
       "      <td>6.627970</td>\n",
       "      <td>17.659895</td>\n",
       "      <td>1.529256e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-28</td>\n",
       "      <td>1</td>\n",
       "      <td>3.472333</td>\n",
       "      <td>223.443172</td>\n",
       "      <td>6.634452</td>\n",
       "      <td>16.448992</td>\n",
       "      <td>1.587566e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-04</td>\n",
       "      <td>1</td>\n",
       "      <td>3.456623</td>\n",
       "      <td>223.409742</td>\n",
       "      <td>6.623966</td>\n",
       "      <td>15.104578</td>\n",
       "      <td>1.678286e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.441573</td>\n",
       "      <td>223.372609</td>\n",
       "      <td>6.592424</td>\n",
       "      <td>13.620766</td>\n",
       "      <td>1.742059e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-18</td>\n",
       "      <td>1</td>\n",
       "      <td>3.423539</td>\n",
       "      <td>223.358492</td>\n",
       "      <td>6.556789</td>\n",
       "      <td>12.028795</td>\n",
       "      <td>1.765627e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>2013-10-06</td>\n",
       "      <td>45</td>\n",
       "      <td>4.393188</td>\n",
       "      <td>195.136141</td>\n",
       "      <td>8.878137</td>\n",
       "      <td>16.570370</td>\n",
       "      <td>7.524903e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>2013-10-13</td>\n",
       "      <td>45</td>\n",
       "      <td>4.400800</td>\n",
       "      <td>195.177228</td>\n",
       "      <td>8.872678</td>\n",
       "      <td>15.371153</td>\n",
       "      <td>7.420480e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>45</td>\n",
       "      <td>4.394871</td>\n",
       "      <td>195.161653</td>\n",
       "      <td>8.877326</td>\n",
       "      <td>13.409695</td>\n",
       "      <td>7.451909e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>2013-10-27</td>\n",
       "      <td>45</td>\n",
       "      <td>4.380892</td>\n",
       "      <td>195.115184</td>\n",
       "      <td>8.887845</td>\n",
       "      <td>11.328064</td>\n",
       "      <td>7.835365e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>2013-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>4.374071</td>\n",
       "      <td>195.052613</td>\n",
       "      <td>8.895672</td>\n",
       "      <td>10.263839</td>\n",
       "      <td>8.378446e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2475 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Store  Fuel_Price         CPI  Unemployment  Temperature_C  \\\n",
       "0     2012-10-21      1    3.487440  223.461145      6.627970      17.659895   \n",
       "1     2012-10-28      1    3.472333  223.443172      6.634452      16.448992   \n",
       "2     2012-11-04      1    3.456623  223.409742      6.623966      15.104578   \n",
       "3     2012-11-11      1    3.441573  223.372609      6.592424      13.620766   \n",
       "4     2012-11-18      1    3.423539  223.358492      6.556789      12.028795   \n",
       "...          ...    ...         ...         ...           ...            ...   \n",
       "2470  2013-10-06     45    4.393188  195.136141      8.878137      16.570370   \n",
       "2471  2013-10-13     45    4.400800  195.177228      8.872678      15.371153   \n",
       "2472  2013-10-20     45    4.394871  195.161653      8.877326      13.409695   \n",
       "2473  2013-10-27     45    4.380892  195.115184      8.887845      11.328064   \n",
       "2474  2013-11-03     45    4.374071  195.052613      8.895672      10.263839   \n",
       "\n",
       "      Weekly_Sales    Label  \n",
       "0     1.529256e+06  Average  \n",
       "1     1.587566e+06  Average  \n",
       "2     1.678286e+06  Average  \n",
       "3     1.742059e+06  Average  \n",
       "4     1.765627e+06  Average  \n",
       "...            ...      ...  \n",
       "2470  7.524903e+05  Average  \n",
       "2471  7.420480e+05  Average  \n",
       "2472  7.451909e+05  Average  \n",
       "2473  7.835365e+05  Average  \n",
       "2474  8.378446e+05  Average  \n",
       "\n",
       "[2475 rows x 8 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranfor_predix = predix\n",
    "ranfor_predix[\"Label\"] = ranfor_labels\n",
    "ranfor_predix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Average    2461\n",
       "Above        14\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranfor_predix[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_labels = logreg.predict(predix_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Average', 'Average', 'Average', ..., 'Average', 'Average',\n",
       "       'Average'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_labels = label_encoder.inverse_transform(logreg_labels)\n",
    "logreg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.487440</td>\n",
       "      <td>223.461145</td>\n",
       "      <td>6.627970</td>\n",
       "      <td>17.659895</td>\n",
       "      <td>1.529256e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-28</td>\n",
       "      <td>1</td>\n",
       "      <td>3.472333</td>\n",
       "      <td>223.443172</td>\n",
       "      <td>6.634452</td>\n",
       "      <td>16.448992</td>\n",
       "      <td>1.587566e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-04</td>\n",
       "      <td>1</td>\n",
       "      <td>3.456623</td>\n",
       "      <td>223.409742</td>\n",
       "      <td>6.623966</td>\n",
       "      <td>15.104578</td>\n",
       "      <td>1.678286e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.441573</td>\n",
       "      <td>223.372609</td>\n",
       "      <td>6.592424</td>\n",
       "      <td>13.620766</td>\n",
       "      <td>1.742059e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-18</td>\n",
       "      <td>1</td>\n",
       "      <td>3.423539</td>\n",
       "      <td>223.358492</td>\n",
       "      <td>6.556789</td>\n",
       "      <td>12.028795</td>\n",
       "      <td>1.765627e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>2013-10-06</td>\n",
       "      <td>45</td>\n",
       "      <td>4.393188</td>\n",
       "      <td>195.136141</td>\n",
       "      <td>8.878137</td>\n",
       "      <td>16.570370</td>\n",
       "      <td>7.524903e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>2013-10-13</td>\n",
       "      <td>45</td>\n",
       "      <td>4.400800</td>\n",
       "      <td>195.177228</td>\n",
       "      <td>8.872678</td>\n",
       "      <td>15.371153</td>\n",
       "      <td>7.420480e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>45</td>\n",
       "      <td>4.394871</td>\n",
       "      <td>195.161653</td>\n",
       "      <td>8.877326</td>\n",
       "      <td>13.409695</td>\n",
       "      <td>7.451909e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>2013-10-27</td>\n",
       "      <td>45</td>\n",
       "      <td>4.380892</td>\n",
       "      <td>195.115184</td>\n",
       "      <td>8.887845</td>\n",
       "      <td>11.328064</td>\n",
       "      <td>7.835365e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>2013-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>4.374071</td>\n",
       "      <td>195.052613</td>\n",
       "      <td>8.895672</td>\n",
       "      <td>10.263839</td>\n",
       "      <td>8.378446e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2475 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Store  Fuel_Price         CPI  Unemployment  Temperature_C  \\\n",
       "0     2012-10-21      1    3.487440  223.461145      6.627970      17.659895   \n",
       "1     2012-10-28      1    3.472333  223.443172      6.634452      16.448992   \n",
       "2     2012-11-04      1    3.456623  223.409742      6.623966      15.104578   \n",
       "3     2012-11-11      1    3.441573  223.372609      6.592424      13.620766   \n",
       "4     2012-11-18      1    3.423539  223.358492      6.556789      12.028795   \n",
       "...          ...    ...         ...         ...           ...            ...   \n",
       "2470  2013-10-06     45    4.393188  195.136141      8.878137      16.570370   \n",
       "2471  2013-10-13     45    4.400800  195.177228      8.872678      15.371153   \n",
       "2472  2013-10-20     45    4.394871  195.161653      8.877326      13.409695   \n",
       "2473  2013-10-27     45    4.380892  195.115184      8.887845      11.328064   \n",
       "2474  2013-11-03     45    4.374071  195.052613      8.895672      10.263839   \n",
       "\n",
       "      Weekly_Sales    Label  \n",
       "0     1.529256e+06  Average  \n",
       "1     1.587566e+06  Average  \n",
       "2     1.678286e+06  Average  \n",
       "3     1.742059e+06  Average  \n",
       "4     1.765627e+06  Average  \n",
       "...            ...      ...  \n",
       "2470  7.524903e+05  Average  \n",
       "2471  7.420480e+05  Average  \n",
       "2472  7.451909e+05  Average  \n",
       "2473  7.835365e+05  Average  \n",
       "2474  8.378446e+05  Average  \n",
       "\n",
       "[2475 rows x 8 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_predix = predix\n",
    "logreg_predix[\"Label\"] = logreg_labels\n",
    "logreg_predix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Average    2475\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_predix[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dectre_labels = dectre.predict(predix_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Average', 'Average', 'Average', ..., 'Average', 'Average',\n",
       "       'Average'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dectre_labels = label_encoder.inverse_transform(dectre_labels)\n",
    "dectre_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.487440</td>\n",
       "      <td>223.461145</td>\n",
       "      <td>6.627970</td>\n",
       "      <td>17.659895</td>\n",
       "      <td>1.529256e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-28</td>\n",
       "      <td>1</td>\n",
       "      <td>3.472333</td>\n",
       "      <td>223.443172</td>\n",
       "      <td>6.634452</td>\n",
       "      <td>16.448992</td>\n",
       "      <td>1.587566e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-04</td>\n",
       "      <td>1</td>\n",
       "      <td>3.456623</td>\n",
       "      <td>223.409742</td>\n",
       "      <td>6.623966</td>\n",
       "      <td>15.104578</td>\n",
       "      <td>1.678286e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.441573</td>\n",
       "      <td>223.372609</td>\n",
       "      <td>6.592424</td>\n",
       "      <td>13.620766</td>\n",
       "      <td>1.742059e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-18</td>\n",
       "      <td>1</td>\n",
       "      <td>3.423539</td>\n",
       "      <td>223.358492</td>\n",
       "      <td>6.556789</td>\n",
       "      <td>12.028795</td>\n",
       "      <td>1.765627e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>2013-10-06</td>\n",
       "      <td>45</td>\n",
       "      <td>4.393188</td>\n",
       "      <td>195.136141</td>\n",
       "      <td>8.878137</td>\n",
       "      <td>16.570370</td>\n",
       "      <td>7.524903e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>2013-10-13</td>\n",
       "      <td>45</td>\n",
       "      <td>4.400800</td>\n",
       "      <td>195.177228</td>\n",
       "      <td>8.872678</td>\n",
       "      <td>15.371153</td>\n",
       "      <td>7.420480e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>45</td>\n",
       "      <td>4.394871</td>\n",
       "      <td>195.161653</td>\n",
       "      <td>8.877326</td>\n",
       "      <td>13.409695</td>\n",
       "      <td>7.451909e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>2013-10-27</td>\n",
       "      <td>45</td>\n",
       "      <td>4.380892</td>\n",
       "      <td>195.115184</td>\n",
       "      <td>8.887845</td>\n",
       "      <td>11.328064</td>\n",
       "      <td>7.835365e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>2013-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>4.374071</td>\n",
       "      <td>195.052613</td>\n",
       "      <td>8.895672</td>\n",
       "      <td>10.263839</td>\n",
       "      <td>8.378446e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2475 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Store  Fuel_Price         CPI  Unemployment  Temperature_C  \\\n",
       "0     2012-10-21      1    3.487440  223.461145      6.627970      17.659895   \n",
       "1     2012-10-28      1    3.472333  223.443172      6.634452      16.448992   \n",
       "2     2012-11-04      1    3.456623  223.409742      6.623966      15.104578   \n",
       "3     2012-11-11      1    3.441573  223.372609      6.592424      13.620766   \n",
       "4     2012-11-18      1    3.423539  223.358492      6.556789      12.028795   \n",
       "...          ...    ...         ...         ...           ...            ...   \n",
       "2470  2013-10-06     45    4.393188  195.136141      8.878137      16.570370   \n",
       "2471  2013-10-13     45    4.400800  195.177228      8.872678      15.371153   \n",
       "2472  2013-10-20     45    4.394871  195.161653      8.877326      13.409695   \n",
       "2473  2013-10-27     45    4.380892  195.115184      8.887845      11.328064   \n",
       "2474  2013-11-03     45    4.374071  195.052613      8.895672      10.263839   \n",
       "\n",
       "      Weekly_Sales    Label  \n",
       "0     1.529256e+06  Average  \n",
       "1     1.587566e+06  Average  \n",
       "2     1.678286e+06  Average  \n",
       "3     1.742059e+06  Average  \n",
       "4     1.765627e+06  Average  \n",
       "...            ...      ...  \n",
       "2470  7.524903e+05  Average  \n",
       "2471  7.420480e+05  Average  \n",
       "2472  7.451909e+05  Average  \n",
       "2473  7.835365e+05  Average  \n",
       "2474  8.378446e+05  Average  \n",
       "\n",
       "[2475 rows x 8 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dectre_predix = predix\n",
    "dectre_predix[\"Label\"] = dectre_labels\n",
    "dectre_predix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Average    2215\n",
       "Above       260\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dectre_predix[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.487440</td>\n",
       "      <td>223.461145</td>\n",
       "      <td>6.627970</td>\n",
       "      <td>17.659895</td>\n",
       "      <td>1.529256e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-28</td>\n",
       "      <td>1</td>\n",
       "      <td>3.472333</td>\n",
       "      <td>223.443172</td>\n",
       "      <td>6.634452</td>\n",
       "      <td>16.448992</td>\n",
       "      <td>1.587566e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-04</td>\n",
       "      <td>1</td>\n",
       "      <td>3.456623</td>\n",
       "      <td>223.409742</td>\n",
       "      <td>6.623966</td>\n",
       "      <td>15.104578</td>\n",
       "      <td>1.678286e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.441573</td>\n",
       "      <td>223.372609</td>\n",
       "      <td>6.592424</td>\n",
       "      <td>13.620766</td>\n",
       "      <td>1.742059e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-18</td>\n",
       "      <td>1</td>\n",
       "      <td>3.423539</td>\n",
       "      <td>223.358492</td>\n",
       "      <td>6.556789</td>\n",
       "      <td>12.028795</td>\n",
       "      <td>1.765627e+06</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>2013-10-06</td>\n",
       "      <td>45</td>\n",
       "      <td>4.393188</td>\n",
       "      <td>195.136141</td>\n",
       "      <td>8.878137</td>\n",
       "      <td>16.570370</td>\n",
       "      <td>7.524903e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>2013-10-13</td>\n",
       "      <td>45</td>\n",
       "      <td>4.400800</td>\n",
       "      <td>195.177228</td>\n",
       "      <td>8.872678</td>\n",
       "      <td>15.371153</td>\n",
       "      <td>7.420480e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>45</td>\n",
       "      <td>4.394871</td>\n",
       "      <td>195.161653</td>\n",
       "      <td>8.877326</td>\n",
       "      <td>13.409695</td>\n",
       "      <td>7.451909e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>2013-10-27</td>\n",
       "      <td>45</td>\n",
       "      <td>4.380892</td>\n",
       "      <td>195.115184</td>\n",
       "      <td>8.887845</td>\n",
       "      <td>11.328064</td>\n",
       "      <td>7.835365e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>2013-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>4.374071</td>\n",
       "      <td>195.052613</td>\n",
       "      <td>8.895672</td>\n",
       "      <td>10.263839</td>\n",
       "      <td>8.378446e+05</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2475 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Store  Fuel_Price         CPI  Unemployment  Temperature_C  \\\n",
       "0     2012-10-21      1    3.487440  223.461145      6.627970      17.659895   \n",
       "1     2012-10-28      1    3.472333  223.443172      6.634452      16.448992   \n",
       "2     2012-11-04      1    3.456623  223.409742      6.623966      15.104578   \n",
       "3     2012-11-11      1    3.441573  223.372609      6.592424      13.620766   \n",
       "4     2012-11-18      1    3.423539  223.358492      6.556789      12.028795   \n",
       "...          ...    ...         ...         ...           ...            ...   \n",
       "2470  2013-10-06     45    4.393188  195.136141      8.878137      16.570370   \n",
       "2471  2013-10-13     45    4.400800  195.177228      8.872678      15.371153   \n",
       "2472  2013-10-20     45    4.394871  195.161653      8.877326      13.409695   \n",
       "2473  2013-10-27     45    4.380892  195.115184      8.887845      11.328064   \n",
       "2474  2013-11-03     45    4.374071  195.052613      8.895672      10.263839   \n",
       "\n",
       "      Weekly_Sales    Label  \n",
       "0     1.529256e+06  Average  \n",
       "1     1.587566e+06  Average  \n",
       "2     1.678286e+06  Average  \n",
       "3     1.742059e+06  Average  \n",
       "4     1.765627e+06  Average  \n",
       "...            ...      ...  \n",
       "2470  7.524903e+05  Average  \n",
       "2471  7.420480e+05  Average  \n",
       "2472  7.451909e+05  Average  \n",
       "2473  7.835365e+05  Average  \n",
       "2474  8.378446e+05  Average  \n",
       "\n",
       "[2475 rows x 8 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predix = pd.read_csv('prophet_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Ave_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.487440</td>\n",
       "      <td>223.461145</td>\n",
       "      <td>6.627970</td>\n",
       "      <td>17.659895</td>\n",
       "      <td>1.529256e+06</td>\n",
       "      <td>1.555264e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-28</td>\n",
       "      <td>1</td>\n",
       "      <td>3.472333</td>\n",
       "      <td>223.443172</td>\n",
       "      <td>6.634452</td>\n",
       "      <td>16.448992</td>\n",
       "      <td>1.587566e+06</td>\n",
       "      <td>1.555264e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-11-04</td>\n",
       "      <td>1</td>\n",
       "      <td>3.456623</td>\n",
       "      <td>223.409742</td>\n",
       "      <td>6.623966</td>\n",
       "      <td>15.104578</td>\n",
       "      <td>1.678286e+06</td>\n",
       "      <td>1.555264e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.441573</td>\n",
       "      <td>223.372609</td>\n",
       "      <td>6.592424</td>\n",
       "      <td>13.620766</td>\n",
       "      <td>1.742059e+06</td>\n",
       "      <td>1.555264e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2012-11-18</td>\n",
       "      <td>1</td>\n",
       "      <td>3.423539</td>\n",
       "      <td>223.358492</td>\n",
       "      <td>6.556789</td>\n",
       "      <td>12.028795</td>\n",
       "      <td>1.765627e+06</td>\n",
       "      <td>1.555264e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>2470</td>\n",
       "      <td>2013-10-06</td>\n",
       "      <td>45</td>\n",
       "      <td>4.393188</td>\n",
       "      <td>195.136141</td>\n",
       "      <td>8.878137</td>\n",
       "      <td>16.570370</td>\n",
       "      <td>7.524903e+05</td>\n",
       "      <td>7.859814e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>2471</td>\n",
       "      <td>2013-10-13</td>\n",
       "      <td>45</td>\n",
       "      <td>4.400800</td>\n",
       "      <td>195.177228</td>\n",
       "      <td>8.872678</td>\n",
       "      <td>15.371153</td>\n",
       "      <td>7.420480e+05</td>\n",
       "      <td>7.859814e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>2472</td>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>45</td>\n",
       "      <td>4.394871</td>\n",
       "      <td>195.161653</td>\n",
       "      <td>8.877326</td>\n",
       "      <td>13.409695</td>\n",
       "      <td>7.451909e+05</td>\n",
       "      <td>7.859814e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>2473</td>\n",
       "      <td>2013-10-27</td>\n",
       "      <td>45</td>\n",
       "      <td>4.380892</td>\n",
       "      <td>195.115184</td>\n",
       "      <td>8.887845</td>\n",
       "      <td>11.328064</td>\n",
       "      <td>7.835365e+05</td>\n",
       "      <td>7.859814e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>2474</td>\n",
       "      <td>2013-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>4.374071</td>\n",
       "      <td>195.052613</td>\n",
       "      <td>8.895672</td>\n",
       "      <td>10.263839</td>\n",
       "      <td>8.378446e+05</td>\n",
       "      <td>7.859814e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2475 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        Date  Store  Fuel_Price         CPI  Unemployment  \\\n",
       "0              0  2012-10-21      1    3.487440  223.461145      6.627970   \n",
       "1              1  2012-10-28      1    3.472333  223.443172      6.634452   \n",
       "2              2  2012-11-04      1    3.456623  223.409742      6.623966   \n",
       "3              3  2012-11-11      1    3.441573  223.372609      6.592424   \n",
       "4              4  2012-11-18      1    3.423539  223.358492      6.556789   \n",
       "...          ...         ...    ...         ...         ...           ...   \n",
       "2470        2470  2013-10-06     45    4.393188  195.136141      8.878137   \n",
       "2471        2471  2013-10-13     45    4.400800  195.177228      8.872678   \n",
       "2472        2472  2013-10-20     45    4.394871  195.161653      8.877326   \n",
       "2473        2473  2013-10-27     45    4.380892  195.115184      8.887845   \n",
       "2474        2474  2013-11-03     45    4.374071  195.052613      8.895672   \n",
       "\n",
       "      Temperature_C  Weekly_Sales     Ave_Sales  \n",
       "0         17.659895  1.529256e+06  1.555264e+06  \n",
       "1         16.448992  1.587566e+06  1.555264e+06  \n",
       "2         15.104578  1.678286e+06  1.555264e+06  \n",
       "3         13.620766  1.742059e+06  1.555264e+06  \n",
       "4         12.028795  1.765627e+06  1.555264e+06  \n",
       "...             ...           ...           ...  \n",
       "2470      16.570370  7.524903e+05  7.859814e+05  \n",
       "2471      15.371153  7.420480e+05  7.859814e+05  \n",
       "2472      13.409695  7.451909e+05  7.859814e+05  \n",
       "2473      11.328064  7.835365e+05  7.859814e+05  \n",
       "2474      10.263839  8.378446e+05  7.859814e+05  \n",
       "\n",
       "[2475 rows x 9 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(predix)):\n",
    "    predix.loc[i, \"Ave_Sales\"] = totalave[predix.loc[i, \"Store\"]]\n",
    "predix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "predix.loc[predix['Weekly_Sales'] > (1.15 * predix[\"Ave_Sales\"]), 'Label'] = 'Above' \n",
    "predix.loc[predix['Weekly_Sales'] < (1.15 * predix[\"Ave_Sales\"]), 'Label'] = 'Average'\n",
    "proph_predix = predix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Average    2071\n",
       "Above       404\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proph_predix[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Average    2461\n",
       "Above        14\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranfor_predix[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Average    2475\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_predix[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Average    2215\n",
       "Above       260\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dectre_predix[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
